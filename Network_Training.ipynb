{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from normalize import Normalize, MapToRange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import *\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "1000 trajectories\n",
      "ready\n",
      "Amount of testing trajectories:  200 (Batchsize: 256)\n",
      "Amount of training trajectories:  800 (Batchsize: 256)\n"
     ]
    }
   ],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i, j = self.indices[index]        \n",
    "        X = torch.tensor([\n",
    "            self.dataset['dx'][i, j],\n",
    "            self.dataset['dy'][i, j],\n",
    "            self.dataset['dz'][i, j],\n",
    "            self.dataset['vx'][i, j],\n",
    "            self.dataset['vy'][i, j],\n",
    "            self.dataset['vz'][i, j],\n",
    "            self.dataset['phi'][i, j],\n",
    "            self.dataset['theta'][i, j],\n",
    "            self.dataset['psi'][i, j],\n",
    "            self.dataset['p'][i, j],\n",
    "            self.dataset['q'][i, j],\n",
    "            self.dataset['r'][i, j],\n",
    "            self.dataset['omega'][i, j, 0],\n",
    "            self.dataset['omega'][i, j, 1],\n",
    "            self.dataset['omega'][i, j, 2],\n",
    "            self.dataset['omega'][i, j, 3],\n",
    "#             self.dataset['Mx_ext'][i],\n",
    "#             self.dataset['My_ext'][i],\n",
    "#             self.dataset['Mz_ext'][i]\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        U = torch.tensor([\n",
    "            self.dataset['u'][i, j, 0],\n",
    "            self.dataset['u'][i, j, 1],\n",
    "            self.dataset['u'][i, j, 2],\n",
    "            self.dataset['u'][i, j, 3]\n",
    "        ], dtype=torch.float32)\n",
    "        \n",
    "        return X, U\n",
    "    \n",
    "# trajectories containing 199 points\n",
    "dataset_path = 'datasets/HOVER_TO_HOVER_NOMINAL.npz'\n",
    "\n",
    "dataset = dict()\n",
    "print('loading dataset...')\n",
    "# See all keys and shapes\n",
    "# with np.load(dataset_path) as data:\n",
    "#     for key in data.files:\n",
    "#         print(key, data[key].shape)\n",
    "\n",
    "with np.load(dataset_path) as full_dataset:\n",
    "    # total number of trajectories\n",
    "    num = len(full_dataset['dx'])\n",
    "    print(num, 'trajectories')\n",
    "    dataset = {key: full_dataset[key] for key in [\n",
    "        't', 'dx', 'dy', 'dz', 'vx', 'vy', 'vz', 'phi', 'theta', 'psi', 'p', 'q', 'r','omega', 'u', 'omega_min','omega_max', 'k_omega', 'Mx_ext', 'My_ext', 'Mz_ext'\n",
    "    ]}\n",
    "\n",
    "# train/test split\n",
    "batchsize_train = 256\n",
    "batchsize_val = 256\n",
    "train_trajectories = range(int(0.8*num))\n",
    "test_trajectories = list(set(range(num)) - set(train_trajectories))\n",
    "\n",
    "train_indices = [(i, j) for i in train_trajectories for j in range(199)]\n",
    "train_set = TrajectoryDataset(dataset, train_indices)\n",
    "train_loader = DataLoader(train_set, batch_size=batchsize_train, shuffle=True, num_workers=1)\n",
    "\n",
    "test_indices = [(i, j) for i in test_trajectories for j in range(199)]\n",
    "test_set = TrajectoryDataset(dataset, test_indices)\n",
    "test_loader = DataLoader(test_set, batch_size=batchsize_val, shuffle=True, num_workers=1)\n",
    "\n",
    "print('ready')\n",
    "\n",
    "print('Amount of testing trajectories: ',len(test_trajectories),f'(Batchsize: {batchsize_val})')\n",
    "print('Amount of training trajectories: ',len(train_trajectories),f'(Batchsize: {batchsize_train})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "800\n",
      "[5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500 5500\n",
      " 5500 5500 5500 5500 5500 5500]\n",
      "[9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500 9500\n",
      " 9500 9500 9500 9500 9500 9500]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_trajectories))\n",
    "print(len(train_trajectories))\n",
    "\n",
    "print(dataset['omega_min'])\n",
    "print(dataset['omega_max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating mean and standard deviation for normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 88392.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "tensor([ 4.1395e-03, -8.1129e-04, -4.9017e-04, -8.1245e-05, -1.9836e-04,\n",
      "        -3.7257e-05, -7.9109e-04,  3.7702e-04, -1.3955e-03,  9.9611e-05,\n",
      "         5.9921e-04,  1.5186e-03,  5.5157e+03,  5.5167e+03,  5.5142e+03,\n",
      "         5.5139e+03])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 79314.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std:\n",
      "tensor([2.1303e-01, 2.4059e-01, 1.2807e-01, 2.1328e-02, 2.5213e-02, 2.1781e-02,\n",
      "        3.3380e-02, 3.0199e-02, 1.3165e-01, 4.7762e-02, 4.8536e-02, 4.8305e-02,\n",
      "        1.8519e+02, 1.8685e+02, 1.6681e+02, 1.6441e+02])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "X_mean = torch.zeros(16)\n",
    "X_std = torch.zeros(16)\n",
    "\n",
    "N=10000\n",
    "\n",
    "for i, data in tqdm(enumerate(test_set)):\n",
    "    X = data[0]\n",
    "    X_mean += X\n",
    "    if i>=N:\n",
    "        break\n",
    "X_mean = X_mean/N\n",
    "\n",
    "print('mean:')\n",
    "print(X_mean)\n",
    "    \n",
    "for i, data in tqdm(enumerate(test_set)):\n",
    "    X = data[0]\n",
    "    X_std += (X-X_mean)**2\n",
    "    if i>=N:\n",
    "        break\n",
    "\n",
    "X_std = torch.sqrt(X_std/N)\n",
    "print('std:')\n",
    "print(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aelarrassi/drone/normalize.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.mean = torch.tensor(mean, dtype=torch.float32)\n",
      "/home/aelarrassi/drone/normalize.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.std = torch.tensor(std, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize()\n",
       "  (1): Linear(in_features=16, out_features=120, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=120, out_features=120, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=120, out_features=120, bias=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=120, out_features=4, bias=True)\n",
       "  (8): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.clamp((-1 / 2048) * x**2 + 0.25 * x + 32, 0.0, 1.0)\n",
    "    \n",
    "class PiecewiseSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.where(x < -2.5, torch.zeros_like(x),\n",
    "               torch.where(x > 2.5, torch.ones_like(x),\n",
    "               0.2 * x + 0.5))\n",
    "class TanhSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * (torch.tanh(x / 2) + 1)\n",
    "    \n",
    "\n",
    "class HardSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(0.2 * x + 0.5, min=0.0, max=1.0)\n",
    "\n",
    "class FastSigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x / (1 + torch.abs(x))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Normalize(mean=X_mean, std=X_std),\n",
    "    nn.Linear(16, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 4),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6702, 0.4503, 0.7526, 0.5665], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(16)\n",
    "print(model(x1))\n",
    "# print([param.shape for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a Loss function and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=1,  threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Current learning rate: 0.0001, Time remaining: -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated!\n",
      "loss = 0.00000113, loss validation = 0.00000124  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 2/100, Current learning rate: 0.0001, Time remaining: 7.27 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000244, loss validation = 0.00000189  (control error: +/-0.14%)\n",
      "\n",
      "Epoch 3/100, Current learning rate: 0.0001, Time remaining: 9.39 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated!\n",
      "loss = 0.00000285, loss validation = 0.00000001  (control error: +/-0.01%)\n",
      "\n",
      "Epoch 4/100, Current learning rate: 0.0001, Time remaining: 8.48 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000124, loss validation = 0.00000177  (control error: +/-0.13%)\n",
      "\n",
      "Epoch 5/100, Current learning rate: 0.0001, Time remaining: 7.41 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000003, loss validation = 0.00000177  (control error: +/-0.13%)\n",
      "\n",
      "Epoch 6/100, Current learning rate: 9e-05, Time remaining: 7.37 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000045, loss validation = 0.00000014  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 7/100, Current learning rate: 9e-05, Time remaining: 7.15 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000025, loss validation = 0.00000002  (control error: +/-0.01%)\n",
      "\n",
      "Epoch 8/100, Current learning rate: 8.1e-05, Time remaining: 7.06 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated!\n",
      "loss = 0.00000031, loss validation = 0.00000000  (control error: +/-0.01%)\n",
      "\n",
      "Epoch 9/100, Current learning rate: 8.1e-05, Time remaining: 6.97 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000044, loss validation = 0.00000140  (control error: +/-0.12%)\n",
      "\n",
      "Epoch 10/100, Current learning rate: 8.1e-05, Time remaining: 7.27 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000026, loss validation = 0.00000113  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 11/100, Current learning rate: 7.290000000000001e-05, Time remaining: 7.51 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000013, loss validation = 0.00000008  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 12/100, Current learning rate: 7.290000000000001e-05, Time remaining: 7.23 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000017, loss validation = 0.00000056  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 13/100, Current learning rate: 6.561000000000002e-05, Time remaining: 6.79 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000018, loss validation = 0.00000002  (control error: +/-0.02%)\n",
      "\n",
      "Epoch 14/100, Current learning rate: 6.561000000000002e-05, Time remaining: 6.61 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000008, loss validation = 0.00000015  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 15/100, Current learning rate: 5.904900000000002e-05, Time remaining: 6.65 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000019, loss validation = 0.00000089  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 16/100, Current learning rate: 5.904900000000002e-05, Time remaining: 7.33 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000022, loss validation = 0.00000108  (control error: +/-0.1%)\n",
      "\n",
      "Epoch 17/100, Current learning rate: 5.314410000000002e-05, Time remaining: 6.7 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000006, loss validation = 0.00000004  (control error: +/-0.02%)\n",
      "\n",
      "Epoch 18/100, Current learning rate: 5.314410000000002e-05, Time remaining: 6.31 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000003, loss validation = 0.00000016  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 19/100, Current learning rate: 4.782969000000002e-05, Time remaining: 6.1 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000004, loss validation = 0.00000145  (control error: +/-0.12%)\n",
      "\n",
      "Epoch 20/100, Current learning rate: 4.782969000000002e-05, Time remaining: 6.18 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000003, loss validation = 0.00000284  (control error: +/-0.17%)\n",
      "\n",
      "Epoch 21/100, Current learning rate: 4.304672100000002e-05, Time remaining: 5.99 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000027  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 22/100, Current learning rate: 4.304672100000002e-05, Time remaining: 6.01 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000010, loss validation = 0.00000022  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 23/100, Current learning rate: 3.874204890000002e-05, Time remaining: 6.05 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000006, loss validation = 0.00000259  (control error: +/-0.16%)\n",
      "\n",
      "Epoch 24/100, Current learning rate: 3.874204890000002e-05, Time remaining: 6.05 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000050  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 25/100, Current learning rate: 3.4867844010000016e-05, Time remaining: 6.36 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000024  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 26/100, Current learning rate: 3.4867844010000016e-05, Time remaining: 5.62 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000048  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 27/100, Current learning rate: 3.138105960900002e-05, Time remaining: 5.51 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000010  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 28/100, Current learning rate: 3.138105960900002e-05, Time remaining: 9.1 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000016  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 29/100, Current learning rate: 2.8242953648100018e-05, Time remaining: 6.05 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000004, loss validation = 0.00000033  (control error: +/-0.06%)\n",
      "\n",
      "Epoch 30/100, Current learning rate: 2.8242953648100018e-05, Time remaining: 5.31 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000004, loss validation = 0.00000003  (control error: +/-0.02%)\n",
      "\n",
      "Epoch 31/100, Current learning rate: 2.5418658283290016e-05, Time remaining: 5.02 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000003, loss validation = 0.00000012  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 32/100, Current learning rate: 2.5418658283290016e-05, Time remaining: 5.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000016  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 33/100, Current learning rate: 2.2876792454961016e-05, Time remaining: 4.94 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000027  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 34/100, Current learning rate: 2.2876792454961016e-05, Time remaining: 4.76 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000123  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 35/100, Current learning rate: 2.0589113209464913e-05, Time remaining: 4.89 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000076  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 36/100, Current learning rate: 2.0589113209464913e-05, Time remaining: 4.89 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000127  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 37/100, Current learning rate: 1.8530201888518422e-05, Time remaining: 4.73 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000037  (control error: +/-0.06%)\n",
      "\n",
      "Epoch 38/100, Current learning rate: 1.8530201888518422e-05, Time remaining: 4.93 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000004, loss validation = 0.00000020  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 39/100, Current learning rate: 1.667718169966658e-05, Time remaining: 4.57 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000031  (control error: +/-0.06%)\n",
      "\n",
      "Epoch 40/100, Current learning rate: 1.667718169966658e-05, Time remaining: 4.43 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000094  (control error: +/-0.1%)\n",
      "\n",
      "Epoch 41/100, Current learning rate: 1.5009463529699922e-05, Time remaining: 4.44 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000003, loss validation = 0.00000006  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 42/100, Current learning rate: 1.5009463529699922e-05, Time remaining: 4.54 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000023  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 43/100, Current learning rate: 1.350851717672993e-05, Time remaining: 4.55 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000016  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 44/100, Current learning rate: 1.350851717672993e-05, Time remaining: 4.17 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000095  (control error: +/-0.1%)\n",
      "\n",
      "Epoch 45/100, Current learning rate: 1.2157665459056937e-05, Time remaining: 4.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000081  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 46/100, Current learning rate: 1.2157665459056937e-05, Time remaining: 4.0 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000147  (control error: +/-0.12%)\n",
      "\n",
      "Epoch 47/100, Current learning rate: 1.0941898913151244e-05, Time remaining: 3.99 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000027  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 48/100, Current learning rate: 1.0941898913151244e-05, Time remaining: 20.72 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000127  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 49/100, Current learning rate: 9.84770902183612e-06, Time remaining: 15.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000087  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 50/100, Current learning rate: 9.84770902183612e-06, Time remaining: 8.32 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000139  (control error: +/-0.12%)\n",
      "\n",
      "Epoch 51/100, Current learning rate: 8.862938119652508e-06, Time remaining: 6.22 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000018  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 52/100, Current learning rate: 8.862938119652508e-06, Time remaining: 5.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000019  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 53/100, Current learning rate: 7.976644307687257e-06, Time remaining: 5.88 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000018  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 54/100, Current learning rate: 7.976644307687257e-06, Time remaining: 5.43 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000117  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 55/100, Current learning rate: 7.1789798769185315e-06, Time remaining: 6.99 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000110  (control error: +/-0.1%)\n",
      "\n",
      "Epoch 56/100, Current learning rate: 7.1789798769185315e-06, Time remaining: 4.51 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000090  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 57/100, Current learning rate: 6.461081889226678e-06, Time remaining: 4.17 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000046  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 58/100, Current learning rate: 6.461081889226678e-06, Time remaining: 4.2 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000080  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 59/100, Current learning rate: 5.81497370030401e-06, Time remaining: 3.83 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000226  (control error: +/-0.15%)\n",
      "\n",
      "Epoch 60/100, Current learning rate: 5.81497370030401e-06, Time remaining: 3.78 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated!\n",
      "loss = 0.00000001, loss validation = 0.00000000  (control error: +/-0.0%)\n",
      "\n",
      "Epoch 61/100, Current learning rate: 5.81497370030401e-06, Time remaining: 3.63 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000002, loss validation = 0.00000055  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 62/100, Current learning rate: 5.81497370030401e-06, Time remaining: 3.33 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000008  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 63/100, Current learning rate: 5.23347633027361e-06, Time remaining: 3.46 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000027  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 64/100, Current learning rate: 5.23347633027361e-06, Time remaining: 3.53 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000075  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 65/100, Current learning rate: 4.710128697246249e-06, Time remaining: 3.34 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000001  (control error: +/-0.01%)\n",
      "\n",
      "Epoch 66/100, Current learning rate: 4.710128697246249e-06, Time remaining: 3.11 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000020  (control error: +/-0.04%)\n",
      "\n",
      "Epoch 67/100, Current learning rate: 4.239115827521624e-06, Time remaining: 3.83 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000082  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 68/100, Current learning rate: 4.239115827521624e-06, Time remaining: 2.74 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000074  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 69/100, Current learning rate: 3.815204244769462e-06, Time remaining: 3.21 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000021  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 70/100, Current learning rate: 3.815204244769462e-06, Time remaining: 2.86 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000003  (control error: +/-0.02%)\n",
      "\n",
      "Epoch 71/100, Current learning rate: 3.4336838202925156e-06, Time remaining: 2.28 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000027  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 72/100, Current learning rate: 3.4336838202925156e-06, Time remaining: 2.19 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000008  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 73/100, Current learning rate: 3.090315438263264e-06, Time remaining: 2.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000052  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 74/100, Current learning rate: 3.090315438263264e-06, Time remaining: 2.04 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000026  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 75/100, Current learning rate: 2.7812838944369375e-06, Time remaining: 2.4 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000063  (control error: +/-0.08%)\n",
      "\n",
      "Epoch 76/100, Current learning rate: 2.7812838944369375e-06, Time remaining: 2.84 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000004, loss validation = 0.00000044  (control error: +/-0.07%)\n",
      "\n",
      "Epoch 77/100, Current learning rate: 2.503155504993244e-06, Time remaining: 2.57 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000011  (control error: +/-0.03%)\n",
      "\n",
      "Epoch 78/100, Current learning rate: 2.503155504993244e-06, Time remaining: 1.92 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000121  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 79/100, Current learning rate: 2.2528399544939195e-06, Time remaining: 1.68 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000073  (control error: +/-0.09%)\n",
      "\n",
      "Epoch 80/100, Current learning rate: 2.2528399544939195e-06, Time remaining: 1.84 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated!\n",
      "loss = 0.00000001, loss validation = 0.00000000  (control error: +/-0.0%)\n",
      "\n",
      "Epoch 81/100, Current learning rate: 2.2528399544939195e-06, Time remaining: 2.26 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000117  (control error: +/-0.11%)\n",
      "\n",
      "Epoch 82/100, Current learning rate: 2.2528399544939195e-06, Time remaining: 1.91 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000025  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 83/100, Current learning rate: 2.0275559590445276e-06, Time remaining: 1.7 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000001, loss validation = 0.00000028  (control error: +/-0.05%)\n",
      "\n",
      "Epoch 84/100, Current learning rate: 2.0275559590445276e-06, Time remaining: 1.58 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000000  (control error: +/-0.0%)\n",
      "\n",
      "Epoch 85/100, Current learning rate: 1.824800363140075e-06, Time remaining: 1.23 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000062  (control error: +/-0.08%)\n",
      "\n",
      "Epoch 86/100, Current learning rate: 1.824800363140075e-06, Time remaining: 1.2 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000057  (control error: +/-0.08%)\n",
      "\n",
      "Epoch 87/100, Current learning rate: 1.6423203268260674e-06, Time remaining: 1.56 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.00000000, loss validation = 0.00000001  (control error: +/-0.01%)\n",
      "\n",
      "Epoch 88/100, Current learning rate: 1.6423203268260674e-06, Time remaining: 1.3 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88/100]:  34%|                     | 212/622 [00:02<00:05, 74.98it/s, loss=2.08e-9]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "loss_list = []\n",
    "loss_val_list = []\n",
    "best_loss = 0.1\n",
    "first = True\n",
    "start_time = time.time()\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model_name = f\"{dataset_path[9:-4]}_{batchsize_train}_{batchsize_val}_{learning_rate}_{num_epochs}\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if first:\n",
    "        time_remaining = '-'\n",
    "    else:\n",
    "        time_estimate = epoch_time*(num_epochs-epoch+1)\n",
    "        if time_estimate > 60:\n",
    "            if time_estimate > 3600:\n",
    "                time_remaining = str(round(time_estimate/3600,2))+' h'\n",
    "            else:\n",
    "                time_remaining = str(round(time_estimate/60,2))+' min'\n",
    "        else:\n",
    "            time_remaining = str(round(time_estimate,0))+' s'\n",
    "        \n",
    "    first = False\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}, Time remaining: {time_remaining}\")\n",
    "\n",
    "    start_time_epoch = time.time()\n",
    "    \n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    for i, (data, targets) in loop:\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progressbar\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    # Validate\n",
    "    with torch.no_grad():\n",
    "        # Get a random batch from the test dataset\n",
    "        data_val, targets_val = next(iter(test_loader))\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_val = model(data_val)\n",
    "\n",
    "        # Loss\n",
    "        loss_val = criterion(outputs_val, targets_val)\n",
    "\n",
    "        if loss_val < best_loss:\n",
    "            # Save best model\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "            # Backup\n",
    "            torch.save(model, 'neural_networks/tmp_benchmark.pt')\n",
    "            \n",
    "            best_loss = loss_val\n",
    "            print(\"Best model updated!\")\n",
    "\n",
    "        # Scheduler (reduce learning rate if loss stagnates)\n",
    "        scheduler.step(loss_val)\n",
    "        \n",
    "        loss_val_list.append(loss_val.item())\n",
    "\n",
    "    print(f'loss = {loss:.8f}, loss validation = {loss_val:.8f} '+r' (control error: +/-'+str(round(100*np.sqrt(float(loss_val)),2))+'%)\\n')\n",
    "\n",
    "    epoch_time = (time.time() - start_time_epoch)\n",
    "\n",
    "    loop.close()\n",
    "    \n",
    "# Compute excecution time\n",
    "execution_time = (time.time() - start_time)    \n",
    "print(f\"Total training time: {round(execution_time,2)}s\")\n",
    "\n",
    "# Save best model and copy for maptorange network\n",
    "torch.save(best_model, f'neural_networks/{nn_model_name}.pt')\n",
    "best_model_for_maptorange = torch.load('neural_networks/tmp_benchmark.pt', weights_only=False)\n",
    "print(best_model_for_maptorange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_val_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plotting loss curves\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mloss_val_list\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss (per batch)\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_val_list)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# plt.plot(running_mean(loss_list, N=100), label='Training Loss (smoothed)', color='blue')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(loss_list)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# plt.plot(\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     np.linspace(0, len(loss_list), len(loss_val_list)), \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     loss_val_list, label='Validation Loss (per epoch)', color='orange'\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_val_list' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute running average (optional: smoother curve)\n",
    "def running_mean(x, N=100):\n",
    "    return np.convolve(x, np.ones(N)/N, mode='valid')\n",
    "\n",
    "# Plotting loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(loss_val_list, label='Validation Loss (per batch)', color='blue', alpha=0.3)\n",
    "print(loss_val_list)\n",
    "# plt.plot(running_mean(loss_list, N=100), label='Training Loss (smoothed)', color='blue')\n",
    "# print(loss_list)\n",
    "# plt.plot(\n",
    "#     np.linspace(0, len(loss_list), len(loss_val_list)), \n",
    "#     loss_val_list, label='Validation Loss (per epoch)', color='orange'\n",
    "# )\n",
    "\n",
    "plt.xlabel('Training Iterations (batches)')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('training.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 3\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mtest_loader\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# loop over the test dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loader = test_loader\n",
    "# loop over the test dataset\n",
    "loop = tqdm(enumerate(loader), total=len(loader), leave=False)\n",
    "running_loss = 0\n",
    "\n",
    "for i, (data, targets) in loop:\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    # update progressbar\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "\n",
    "loop.close()\n",
    "print('average loss =', running_loss/len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'neural_networks/HOVER_TO_HOVER_NOMINAL.pt')\n",
    "torch.save({'network_state_dict': model.state_dict()}, 'neural_networks/Drone_customsigmoid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('neural_networks/HOVER_TO_HOVER_NOMINAL.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': array([[0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ],\n",
      "       [0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ],\n",
      "       [0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ],\n",
      "       ...,\n",
      "       [0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ],\n",
      "       [0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ],\n",
      "       [0.        , 0.01010101, 0.02020202, ..., 1.97979798, 1.98989899,\n",
      "        2.        ]]), 'dx': array([[-2.40801061, -1.20715474,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 2.13752423,  1.0618441 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.09140051,  0.05229611,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [-1.01808148, -0.51022048,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 2.99824375,  1.50590399,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.84143403,  0.41614872,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'dy': array([[-2.34039708, -1.16457512,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 4.77723767,  2.38989406,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-4.802877  , -2.40469152,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 3.70202581,  1.84798861,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 4.20080589,  2.09576688,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 1.70508725,  0.8551986 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'dz': array([[ 2.37421985,  1.1877915 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.61222121,  0.31127518,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 2.08172631,  1.03130449,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [-0.9757216 , -0.4986491 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.15962459, -0.07945099,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.73587969, -0.3665805 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'vx': array([[-0.30794683, -0.14019432,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.17975264, -0.09406655,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.37374181,  0.17637145,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.46821586,  0.23772976,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.01246599,  0.00560475,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.20095473,  0.11146335,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'vy': array([[-0.47942505, -0.23669788,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.47880187,  0.23527503,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.18914233, -0.08851499,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.02826094,  0.01875951,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.06405774, -0.0378373 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.02934049,  0.01778074,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'vz': array([[-0.12460803, -0.07632633,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ],\n",
      "       [ 0.47065353,  0.22025436,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ],\n",
      "       [ 0.24568318,  0.09608377,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ],\n",
      "       ...,\n",
      "       [-0.16562716, -0.09913485,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ],\n",
      "       [ 0.0686368 ,  0.0137563 ,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ],\n",
      "       [ 0.1270254 ,  0.04769693,  0.        , ...,  0.        ,\n",
      "         0.01144131,  0.        ]]), 'phi': array([[ 0.09594464,  0.04581405,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.10036649, -0.05257657,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.25430154,  0.12453504,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.19494056,  0.09985747,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.27516051, -0.13812954,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.14152827,  0.06940395,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'theta': array([[-0.63691914, -0.31931203,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.17539386,  0.08577891,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.43004417,  0.21606537,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [-0.14832148, -0.0716718 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.50392473, -0.25106167,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.45487918, -0.2296385 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'psi': array([[-1.15806462, -0.57623495,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-2.35673174, -1.17997369,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.3329864 ,  0.16471044,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [-2.72450559, -1.36241026,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 1.3179419 ,  0.66056542,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 3.13129713,  1.5637924 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'p': array([[-0.19587054,  0.14548545,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.83665624, -0.25196285,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.74150143, -0.36349293,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.9361145 ,  0.23022139,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.08736897,  0.2105541 ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.86157725, -0.69772514,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'q': array([[-0.25070958, -0.15031952,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.69289506, -0.38734039,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.23842377,  0.16412475,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 0.95500559,  0.43618762,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.19302492,  0.25375773,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.95520121, -0.48168431,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'r': array([[ 0.91880327,  0.45303354,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.6998792 , -0.33499143,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.72498953, -0.35816661,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [-0.251425  , -0.12628263,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.62903177,  0.30438626,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [-0.53086917, -0.25340124,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), 'omega': array([[[7775.81284819, 6211.98251016, 5855.15081529, 8451.21641624],\n",
      "        [6542.12305506, 5826.02566122, 5662.62798276, 6851.39876299],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]],\n",
      "\n",
      "       [[9045.45313044, 6186.88069304, 8172.09317797, 8276.24243075],\n",
      "        [7123.50715737, 5814.53122644, 6723.58475489, 6771.27599523],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]],\n",
      "\n",
      "       [[9437.30691784, 9090.01818598, 9048.85150349, 8724.92978474],\n",
      "        [7302.9418883 , 7143.91405149, 7125.06331473, 6976.73552433],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[6971.0444809 , 8849.07100572, 9462.28142772, 7670.2081205 ],\n",
      "        [6173.60959395, 7033.58133595, 7314.37802751, 6493.76533464],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]],\n",
      "\n",
      "       [[9395.79252748, 8889.11041949, 5948.58973839, 8260.2238545 ],\n",
      "        [7283.93193178, 7051.91588233, 5705.4148297 , 6763.9408896 ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]],\n",
      "\n",
      "       [[6992.05993414, 8103.83218529, 9202.43153777, 5839.17098456],\n",
      "        [6183.23283179, 6692.32719596, 7195.38952571, 5655.31061919],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        ...,\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ],\n",
      "        [5500.        , 5500.        , 5500.        , 5500.        ]]]), 'u': array([[[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]],\n",
      "\n",
      "       [[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]],\n",
      "\n",
      "       [[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]],\n",
      "\n",
      "       [[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]],\n",
      "\n",
      "       [[0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        ...,\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5],\n",
      "        [0.5, 0.5, 0.5, 0.5]]]), 'omega_min': array([5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500,\n",
      "       5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500, 5500]), 'omega_max': array([9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500,\n",
      "       9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500, 9500]), 'k_omega': array(4.36301076e-08), 'Mx_ext': array([-0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0., -0.,\n",
      "        0., -0.,  0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0.,\n",
      "       -0., -0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0., -0.,  0.,  0., -0., -0., -0.,  0., -0.,  0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0.,  0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "        0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,\n",
      "        0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,\n",
      "        0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0., -0., -0.,\n",
      "       -0., -0., -0., -0., -0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,\n",
      "        0., -0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0.,\n",
      "       -0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0., -0., -0., -0.,  0., -0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0., -0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0., -0.,  0.,  0., -0., -0., -0., -0.,  0.,  0., -0., -0., -0.,\n",
      "       -0., -0., -0., -0.,  0.,  0., -0., -0., -0., -0.,  0., -0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "        0., -0., -0., -0.,  0.,  0., -0.,  0., -0., -0., -0., -0.,  0.,\n",
      "        0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "       -0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,\n",
      "       -0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.,\n",
      "        0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "        0.,  0.,  0., -0., -0., -0., -0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0.,  0.,  0., -0., -0.,  0., -0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0., -0.,\n",
      "       -0.,  0.,  0., -0., -0., -0., -0., -0., -0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "        0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "       -0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,\n",
      "        0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0., -0., -0.,  0.,  0., -0., -0., -0., -0.,  0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,  0.,  0., -0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,\n",
      "       -0.,  0.,  0., -0.,  0.,  0., -0., -0., -0.,  0.,  0., -0., -0.,\n",
      "        0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0., -0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0., -0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0., -0., -0.,\n",
      "       -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "        0., -0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0.,  0., -0., -0., -0., -0., -0.,  0.,\n",
      "        0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
      "       -0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "       -0.,  0., -0., -0., -0.,  0., -0., -0.,  0.,  0., -0., -0.,  0.,\n",
      "        0., -0.,  0., -0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "        0.,  0., -0.,  0.,  0., -0., -0., -0., -0.,  0.,  0., -0.,  0.,\n",
      "        0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0., -0., -0., -0.,  0., -0., -0., -0.,  0., -0., -0., -0., -0.,\n",
      "        0., -0., -0.,  0., -0., -0., -0., -0., -0.,  0., -0.,  0.,  0.,\n",
      "       -0., -0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.,\n",
      "       -0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0.,  0., -0., -0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0., -0., -0., -0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "       -0.,  0., -0., -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "        0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "        0., -0.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,  0.]), 'My_ext': array([ 0., -0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0.,\n",
      "       -0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "       -0., -0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,\n",
      "        0., -0., -0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0., -0.,\n",
      "        0.,  0.,  0., -0.,  0.,  0., -0., -0., -0., -0., -0.,  0.,  0.,\n",
      "        0.,  0., -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0., -0., -0., -0., -0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "       -0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0., -0., -0., -0.,\n",
      "       -0., -0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "        0., -0., -0., -0., -0., -0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "       -0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0.,  0., -0., -0., -0., -0., -0.,  0., -0., -0.,  0.,\n",
      "        0.,  0., -0., -0.,  0., -0.,  0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "       -0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "        0., -0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,\n",
      "       -0., -0., -0.,  0.,  0., -0., -0., -0., -0., -0., -0.,  0., -0.,\n",
      "        0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0.,  0.,\n",
      "       -0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "        0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0.,\n",
      "       -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0., -0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "       -0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,\n",
      "        0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0., -0.,\n",
      "       -0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "        0., -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,\n",
      "        0.,  0.,  0., -0., -0., -0., -0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0., -0., -0., -0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "        0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0., -0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0., -0., -0.,  0.,\n",
      "       -0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "        0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0., -0., -0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "       -0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0., -0., -0.,\n",
      "        0., -0., -0., -0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0., -0., -0., -0., -0., -0.,  0.,  0.,\n",
      "        0., -0., -0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0.,\n",
      "        0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "        0., -0.,  0.,  0., -0., -0., -0.,  0.,  0., -0., -0., -0., -0.,\n",
      "        0.,  0., -0., -0., -0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0.,  0., -0., -0., -0.,\n",
      "       -0., -0.,  0., -0., -0., -0.,  0.,  0., -0., -0., -0.,  0.,  0.,\n",
      "        0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0., -0.,\n",
      "       -0., -0.,  0.,  0., -0., -0., -0., -0., -0.,  0., -0., -0., -0.,\n",
      "       -0., -0.,  0., -0., -0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0., -0., -0., -0., -0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0., -0.,  0., -0., -0., -0., -0.,  0.,\n",
      "        0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0., -0.,\n",
      "       -0.,  0., -0., -0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0.,  0.,  0., -0., -0., -0., -0., -0.,\n",
      "       -0., -0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "       -0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0.,\n",
      "        0.,  0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "        0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,\n",
      "       -0.,  0.,  0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0., -0.,\n",
      "       -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0., -0., -0.,  0.,\n",
      "        0., -0., -0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0., -0., -0.,\n",
      "        0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0., -0., -0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0.]), 'Mz_ext': array([-0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0.,  0.,\n",
      "        0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,  0., -0., -0.,  0.,\n",
      "        0.,  0., -0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0., -0.,\n",
      "       -0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0., -0., -0.,\n",
      "        0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0.,  0., -0.,  0., -0.,  0., -0., -0., -0., -0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,  0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,\n",
      "       -0., -0., -0., -0.,  0., -0.,  0., -0., -0., -0.,  0.,  0., -0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.,\n",
      "        0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
      "       -0., -0., -0., -0.,  0., -0., -0., -0., -0.,  0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.,  0., -0., -0., -0.,\n",
      "        0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,\n",
      "       -0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,\n",
      "       -0., -0., -0., -0., -0.,  0., -0.,  0., -0., -0.,  0., -0., -0.,\n",
      "        0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,  0., -0.,\n",
      "       -0., -0.,  0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "        0.,  0., -0., -0.,  0.,  0., -0., -0.,  0., -0., -0., -0., -0.,\n",
      "       -0.,  0., -0.,  0., -0., -0., -0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0., -0., -0.,  0.,\n",
      "        0., -0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0., -0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,  0.,\n",
      "       -0.,  0., -0., -0., -0., -0.,  0., -0., -0., -0.,  0., -0., -0.,\n",
      "        0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "       -0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0., -0.,\n",
      "       -0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "        0.,  0., -0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
      "       -0., -0.,  0., -0.,  0.,  0., -0.,  0., -0.,  0., -0., -0., -0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0., -0.,\n",
      "       -0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,  0.,  0.,  0., -0.,\n",
      "       -0., -0., -0.,  0., -0., -0.,  0., -0., -0.,  0., -0., -0., -0.,\n",
      "       -0., -0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0.,\n",
      "        0., -0., -0.,  0., -0., -0., -0.,  0., -0.,  0., -0.,  0.,  0.,\n",
      "        0., -0.,  0., -0., -0., -0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "        0., -0.,  0., -0., -0.,  0., -0.,  0.,  0., -0.,  0., -0., -0.,\n",
      "       -0., -0., -0., -0.,  0.,  0.,  0., -0., -0., -0., -0., -0., -0.,\n",
      "       -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0., -0., -0.,  0., -0.,\n",
      "        0., -0.,  0.,  0., -0., -0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,\n",
      "        0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0., -0.,\n",
      "       -0.,  0.,  0., -0.,  0.,  0., -0., -0., -0., -0.,  0., -0.,  0.,\n",
      "        0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
      "        0., -0., -0., -0., -0.,  0., -0., -0.,  0.,  0., -0., -0.,  0.,\n",
      "        0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0., -0., -0.,  0., -0.,\n",
      "        0., -0., -0., -0., -0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
      "       -0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0., -0.,  0.,\n",
      "        0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.,\n",
      "        0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,\n",
      "        0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0., -0., -0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0.,\n",
      "        0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
      "        0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0., -0.,  0.,\n",
      "        0., -0.,  0.,  0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0., -0.,  0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0.,  0.,\n",
      "        0., -0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0., -0., -0.,  0., -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,\n",
      "       -0., -0.,  0., -0., -0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "       -0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0., -0., -0., -0.,  0.,\n",
      "        0.,  0.,  0., -0.,  0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,\n",
      "        0., -0., -0., -0., -0., -0.,  0., -0., -0.,  0.,  0., -0., -0.,\n",
      "        0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0.,  0., -0., -0., -0., -0., -0.,  0., -0., -0.,\n",
      "       -0., -0., -0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0., -0., -0., -0., -0., -0., -0.,  0.,  0., -0.,  0., -0.,\n",
      "        0.,  0., -0.,  0., -0.,  0., -0., -0., -0., -0.,  0.,  0.,  0.,\n",
      "       -0.,  0., -0., -0., -0., -0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
      "        0., -0., -0.,  0., -0.,  0.,  0., -0., -0., -0.,  0., -0., -0.,\n",
      "       -0., -0.,  0.,  0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0.])}\n"
     ]
    }
   ],
   "source": [
    "model_processed_output =nn.Sequential(\n",
    "    *model,\n",
    "    MapToRange(dataset['omega_min'], dataset['omega_max'])\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "torch.save(model_processed_output, 'neural_networks/HOVER_TO_HOVER_NOMINAL_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize()\n",
      "Sequential(\n",
      "  (0): Normalize()\n",
      "  (1): DynamicQuantizedLinear(in_features=16, out_features=120, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (2): ReLU()\n",
      "  (3): DynamicQuantizedLinear(in_features=120, out_features=120, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (4): ReLU()\n",
      "  (5): DynamicQuantizedLinear(in_features=120, out_features=120, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (6): ReLU()\n",
      "  (7): DynamicQuantizedLinear(in_features=120, out_features=4, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (8): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load your trained model\n",
    "model = torch.load('neural_networks/tmp_benchmark.pt', weights_only=False)\n",
    "print(model[0])\n",
    "\n",
    "# Apply dynamic quantization (works on Linear, LSTM)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(quantized_model)\n",
    "# Save quantized model\n",
    "torch.save({'network_state_dict': model.state_dict()}, 'neural_networks/tmp_benchmark_quantized1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Redbit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRedbit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantLinear  \u001b[38;5;66;03m# RedBit layer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load your original model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Redbit'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Redbit.nn import QuantLinear  # RedBit layer\n",
    "from copy import deepcopy\n",
    "\n",
    "# Load your original model\n",
    "model = torch.load('neural_networks/tmp_benchmark.pt', weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "# Replace all Linear layers with QuantLinear\n",
    "def replace_linear_with_quant(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            quant_layer = QuantLinear(\n",
    "                in_features=child.in_features,\n",
    "                out_features=child.out_features,\n",
    "                bias=child.bias is not None,\n",
    "                bit=8  # <-- 8-bit quantization\n",
    "            )\n",
    "            quant_layer.weight.data = deepcopy(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                quant_layer.bias.data = deepcopy(child.bias.data)\n",
    "            setattr(module, name, quant_layer)\n",
    "        else:\n",
    "            replace_linear_with_quant(child)\n",
    "\n",
    "replace_linear_with_quant(model)\n",
    "\n",
    "# Save the modified model\n",
    "torch.save(model, 'neural_networks/tmp_benchmark_redbit_quantized.pt')\n",
    "load\n",
    "\n",
    "# Optional: print the quantized model\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantized_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use quantized model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mquantized_model\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m loader \u001b[38;5;241m=\u001b[39m test_loader\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quantized_model' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Use quantized model\n",
    "model = quantized_model\n",
    "model.eval()\n",
    "\n",
    "loader = test_loader\n",
    "running_loss = 0\n",
    "\n",
    "loop = tqdm(enumerate(loader), total=len(loader), leave=False)\n",
    "\n",
    "for i, (data, targets) in loop:\n",
    "    data = data.cpu()      # ensure inputs are on CPU\n",
    "    targets = targets.cpu()\n",
    "\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "\n",
    "loop.close()\n",
    "print('average loss =', running_loss / len(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total quantized weights (absolute values) in model: 31200\n",
      "\n",
      "Global quantized weight distribution (absolute values) saved to: quantized_weight_analysis_global_abs.csv\n"
     ]
    }
   ],
   "source": [
    "# Hamming distance\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import csv\n",
    "\n",
    "# Load the quantized model\n",
    "model = torch.load('neural_networks/tmp_benchmark_quantized.pt', weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "# Hamming distance between 8-bit integers\n",
    "def hamming_distance(a, b=0):\n",
    "    return bin(a ^ b).count(\"1\")\n",
    "\n",
    "# Initialize total counter for all layers (using absolute values)\n",
    "global_counter = collections.Counter()\n",
    "global_total = 0\n",
    "\n",
    "# Aggregate all quantized weights (absolute values) across all layers\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.quantized.dynamic.Linear):\n",
    "        weight = module._packed_params._weight_bias()[0]\n",
    "        flat = weight.int_repr().view(-1).cpu().numpy()\n",
    "        flat_abs = abs(flat)  # take absolute values\n",
    "        global_counter.update(flat_abs)\n",
    "        global_total += flat_abs.size\n",
    "\n",
    "print(f\"\\nTotal quantized weights (absolute values) in model: {global_total}\")\n",
    "\n",
    "# Output file\n",
    "output_csv = \"quantized_weight_analysis_global_abs.csv\"\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)            \n",
    "    writer.writerow([\"Quantized Value (abs)\", \"Count\", \"Percentage\", \"Hamming Distance\", \"Hamming x Percentage\"])\n",
    "\n",
    "    # Values from 0 to 127 since we're using absolute values\n",
    "    for val in range(0, 128):\n",
    "        count = global_counter.get(val, 0)\n",
    "        percentage = (count / global_total) * 100 if global_total > 0 else 0\n",
    "        hamming = hamming_distance(val & 0xFF, 0)  # 8-bit representation of abs value\n",
    "        weighted_hamming = hamming * percentage\n",
    "\n",
    "        writer.writerow([\n",
    "            val,\n",
    "            count,\n",
    "            f\"{percentage:.2f}\",\n",
    "            hamming,\n",
    "            f\"{weighted_hamming:.2f}\"\n",
    "        ])\n",
    "\n",
    "print(f\"\\nGlobal quantized weight distribution (absolute values) saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/RedBit/QNN/')  # Adjust path as needed\n",
    "import torch.nn as nn\n",
    "from tools import *\n",
    "\n",
    "class QuantizedModel(nn.Module):\n",
    "    def __init__(self, wbits=4, abits=4):\n",
    "        super(QuantizedModel, self).__init__()\n",
    "        self.abits = abits\n",
    "        self.wbits = wbits\n",
    "\n",
    "        if self.abits == 32:\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            self.act = nn.Hardtanh(inplace=True)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Normalize(mean=X_mean, std=X_std),\n",
    "\n",
    "            QLinear(abits=self.abits, wbits=self.wbits, in_features=16, out_features=120, bias=False),\n",
    "            nn.BatchNorm1d(120, eps=1e-4, momentum=0.1, affine=True),\n",
    "            self.act,\n",
    "\n",
    "            QLinear(abits=self.abits, wbits=self.wbits, in_features=120, out_features=120, bias=False),\n",
    "            nn.BatchNorm1d(120, eps=1e-4, momentum=0.1, affine=True),\n",
    "            self.act,\n",
    "\n",
    "            QLinear(abits=self.abits, wbits=self.wbits, in_features=120, out_features=120, bias=False),\n",
    "            nn.BatchNorm1d(120, eps=1e-4, momentum=0.1, affine=True),\n",
    "            self.act,\n",
    "\n",
    "            QLinear(abits=self.abits, wbits=self.wbits, in_features=120, out_features=4, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/RedBit/QNN/', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/aelarrassi/environments/drone_env/lib/python3.10/site-packages', '/tmp/tmplsdnbq2l']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'QuantizedModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneural_networks/tmp_benchmark.pt\u001b[39m\u001b[38;5;124m'\u001b[39m , weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Quantize to 4-bit weights and activations\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mQuantizedModel\u001b[49m(model)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[1;32m     33\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(quantized_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneural_networks/tmp_benchmark_quantized_int4.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'QuantizedModel' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'/home/RedBit/QNN/models/')  # Adjust path as needed\n",
    "# sys.path.remove('/home/RedBit/Baseline/tools/')\n",
    "# Remove wrong path\n",
    "wrong_path = '/home/RedBit/Baseline/tools'\n",
    "if wrong_path in sys.path:\n",
    "    sys.path.remove(wrong_path)\n",
    "\n",
    "# Force correct path at the front\n",
    "correct_path = '/home/RedBit/QNN/'\n",
    "if correct_path in sys.path:\n",
    "    sys.path.remove(correct_path)\n",
    "sys.path.insert(0, correct_path)\n",
    "\n",
    "# Clear cached wrong module\n",
    "if 'tools' in sys.modules:\n",
    "    del sys.modules['tools']\n",
    "print(sys.path)\n",
    "from tools import quantization\n",
    "# from quantization import QLinear\n",
    "# from RedBit.quantizer import quantize_pytorch_model\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = torch.load('neural_networks/tmp_benchmark.pt' , weights_only=False)\n",
    "\n",
    "# Quantize to 4-bit weights and activations\n",
    "quantized_model = QuantizedModel(model)\n",
    "\n",
    "# Save\n",
    "torch.save(quantized_model, 'neural_networks/tmp_benchmark_quantized_int4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'QuantizedModel' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load quantized model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m quantized_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneural_networks/tmp_benchmark_quantized_int4.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m quantized_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Your existing test loop\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1524\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1533\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/serialization.py:2114\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   2113\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 2114\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2115\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2117\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/serialization.py:2103\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 2103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'QuantizedModel' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# from quantizer import quantize_pytorch_model\n",
    "import torch\n",
    "# Load quantized model\n",
    "quantized_model = torch.load('neural_networks/tmp_benchmark_quantized_int4.pt', weights_only=False)\n",
    "quantized_model.eval()\n",
    "\n",
    "# Your existing test loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "loader = test_loader\n",
    "loop = tqdm(enumerate(loader), total=len(loader), leave=False)\n",
    "running_loss = 0\n",
    "\n",
    "for i, (data, targets) in loop:\n",
    "    outputs = quantized_model(data)\n",
    "    loss = criterion(outputs, targets)\n",
    "    running_loss += loss.item()\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "\n",
    "loop.close()\n",
    "print('average loss =', running_loss / len(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (drone_env)",
   "language": "python",
   "name": "drone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
