{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brazilian-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from numpy import sin, cos, tan\n",
    "from scipy import integrate\n",
    "from quadcopter_animation import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assured-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('neural_networks/HOVER_TO_HOVER_NOMINAL_.pt', weights_only=False)\n",
    "model.eval()\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffdd2b34",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (1000) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# def neural_network(X):  # Assuming X has shape (16,)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         X = X[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]  # shape (16,)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         X = torch.tensor(X, dtype=torch.float32).unsqueeze(0)  # shape (1, 16)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         u = model(X).detach().numpy()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         return u\u001b[39;00m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m16\u001b[39m)  \u001b[38;5;66;03m# or whatever input size you suspect\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/drone_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/drone/normalize.py:20\u001b[0m, in \u001b[0;36mMapToRange.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin \u001b[38;5;241m+\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (1000) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "def neural_network(X): #Mx, My, Mz):\n",
    "    with torch.no_grad():\n",
    "        X = list(X[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]])\n",
    "        print(model)\n",
    "        u = model(torch.tensor(X, dtype=torch.float32)).detach().numpy()\n",
    "        return u\n",
    "\n",
    "# def neural_network(X):  # Assuming X has shape (16,)\n",
    "#     with torch.no_grad():\n",
    "#         X = X[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]  # shape (16,)\n",
    "#         X = torch.tensor(X, dtype=torch.float32).unsqueeze(0)  # shape (1, 16)\n",
    "#         u = model(X).detach().numpy()\n",
    "#         return u\n",
    "\n",
    "x = torch.randn(1, 16, 4)  # or whatever input size you suspect\n",
    "output = model(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "neural_network(np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    # TRANSFORM COORDINATES TO BODY FRAME\n",
    "    x, y, z, vx, vy, vz, phi, theta, psi, p, q, r, utau1, utau2, utau3, utau4 = X\n",
    "    Rx = np.array([[1, 0, 0], [0, np.cos(phi), -np.sin(phi)], [0, np.sin(phi), np.cos(phi)]])\n",
    "    Ry = np.array([[np.cos(theta), 0, np.sin(theta)], [0, 1, 0], [-np.sin(theta), 0, np.cos(theta)]])\n",
    "    Rz = np.array([[np.cos(psi), -np.sin(psi), 0], [np.sin(psi), np.cos(psi), 0], [0, 0, 1]])\n",
    "    R = Rz@Ry@Rx\n",
    "    \n",
    "    # new state variables\n",
    "    xn, yn, zn = -R.T@[x,y,z]\n",
    "    vxn, vyn, vzn = R.T@[vx,vy,vz]\n",
    "    \n",
    "    Xn = np.array([xn, yn, zn, vxn, vyn, vzn, phi, theta, psi, p, q, r, utau1, utau2, utau3, utau4])\n",
    "    return Xn\n",
    "\n",
    "def transform_back(X):\n",
    "    # TRANSFORM COORDINATES TO WORLD FRAME\n",
    "    x, y, z, vx, vy, vz, phi, theta, psi, p, q, r, utau1, utau2, utau3, utau4 = X\n",
    "    Rx = np.array([[1, 0, 0], [0, np.cos(phi), -np.sin(phi)], [0, np.sin(phi), np.cos(phi)]])\n",
    "    Ry = np.array([[np.cos(theta), 0, np.sin(theta)], [0, 1, 0], [-np.sin(theta), 0, np.cos(theta)]])\n",
    "    Rz = np.array([[np.cos(psi), -np.sin(psi), 0], [np.sin(psi), np.cos(psi), 0], [0, 0, 1]])\n",
    "    R = Rz@Ry@Rx\n",
    "    \n",
    "    # new state variables\n",
    "    xn, yn, zn = -R@[x,y,z]\n",
    "    vxn, vyn, vzn = R@[vx,vy,vz]\n",
    "    \n",
    "    Xn = np.array([xn, yn, zn, vxn, vyn, vzn, phi, theta, psi, p, q, r, utau1, utau2, utau3, utau4])\n",
    "    return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory dataset\n",
    "dataset_path = 'datasets/free_final_velocity_tau=0.06_no_moments.npz'\n",
    "dataset = np.load(dataset_path)\n",
    "\n",
    "g         = dataset['g']\n",
    "mass      = dataset['mass']\n",
    "Ixx       = dataset['Ixx']\n",
    "Iyy       = dataset['Iyy']\n",
    "Izz       = dataset['Izz']\n",
    "\n",
    "k_x       = dataset['k_x']\n",
    "k_y       = dataset['k_y']\n",
    "k_z       = dataset['k_z']\n",
    "k_omega   = dataset['k_omega']\n",
    "k_h       = dataset['k_h']\n",
    "k_p       = dataset['k_p']\n",
    "k_pv      = dataset['k_pv']\n",
    "k_q       = dataset['k_q']\n",
    "k_qv      = dataset['k_qv']\n",
    "k_r1      = dataset['k_r1']\n",
    "k_r2      = dataset['k_r2']\n",
    "k_rr      = dataset['k_rr']\n",
    "\n",
    "omega_max = dataset['omega_max']\n",
    "omega_min = dataset['omega_min']\n",
    "tau       = dataset['tau']\n",
    "\n",
    "print(omega_min, omega_max)\n",
    "print(dataset['dx'].shape)\n",
    "print(tau)\n",
    "\n",
    "print(g, Ixx, Iyy, Izz, k_x, k_y, k_z, k_omega, k_h, k_p, k_pv, k_q, k_qv, k_r1, k_r2, k_rr, tau, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2838f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mx, My, Mz = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b242e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(t, y, u):    \n",
    "    # state\n",
    "    dx, dy, dz, vx, vy, vz, phi, theta, psi, p, q, r, omega1, omega2, omega3, omega4 = y\n",
    "    \n",
    "    # control input\n",
    "    u1, u2, u3, u4 = u\n",
    "    \n",
    "    d_dx    = -q*dz + r*dy - vx\n",
    "    d_dy    =  p*dz - r*dx - vy\n",
    "    d_dz    = -p*dy + q*dx - vz\n",
    "    \n",
    "    omegas = omega1 + omega2 + omega3 + omega4\n",
    "    omegas2 = omega1**2 + omega2**2 + omega3**2 + omega4**2\n",
    "    \n",
    "    d_vx    = -q*vz + r*vy - g*sin(theta) - k_x*omegas*vx\n",
    "    d_vy    =  p*vz - r*vx + g*cos(theta)*sin(phi) - k_y*omegas*vy\n",
    "    d_vz    = -p*vy + q*vx + g*cos(theta)*cos(phi) - k_z*omegas*vz - k_omega*omegas2 - k_h*(vx**2+vy**2)\n",
    "    \n",
    "    d_phi   = p + q*sin(phi)*tan(theta) + r*cos(phi)*tan(theta)\n",
    "    d_theta = q*cos(phi) - r*sin(phi)\n",
    "    d_psi   = q*sin(phi)/cos(theta) + r*cos(phi)/cos(theta)\n",
    "    \n",
    "    d_omega1 = (omega_min + u1*(omega_max - omega_min)-omega1)/tau\n",
    "    d_omega2 = (omega_min + u2*(omega_max - omega_min)-omega2)/tau\n",
    "    d_omega3 = (omega_min + u3*(omega_max - omega_min)-omega3)/tau\n",
    "    d_omega4 = (omega_min + u4*(omega_max - omega_min)-omega4)/tau\n",
    "    \n",
    "    taux = k_p*(omega1**2-omega2**2-omega3**2+omega4**2) + k_pv*vy + Mx\n",
    "    tauy = k_q*(omega1**2+omega2**2-omega3**2-omega4**2) + k_qv*vx + My\n",
    "    tauz = k_r1*(-omega1+omega2-omega3+omega4) + k_r2*(-d_omega1+d_omega2-d_omega3+d_omega4) - k_rr*r + Mz\n",
    "    \n",
    "    d_p     = (q*r*(Iyy-Izz) + taux)/Ixx\n",
    "    d_q     = (p*r*(Izz-Ixx) + tauy)/Iyy\n",
    "    d_r     = (p*q*(Ixx-Iyy) + tauz)/Izz\n",
    "    \n",
    "    return np.array([d_dx, d_dy, d_dz, d_vx, d_vy, d_vz, d_phi, d_theta, d_psi, d_p, d_q, d_r, d_omega1, d_omega2, d_omega3, d_omega4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67438db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### longer time\n",
    "t = np.linspace(0,20,20000)\n",
    "\n",
    "y_0= np.zeros(16)\n",
    "y_0[12:16] = (omega_max+omega_min)/2\n",
    "y_0[0] = 4.\n",
    "y_0[1] = 0.\n",
    "y_0[8] = 0.*np.pi/2\n",
    "\n",
    "def dydt(t, y):\n",
    "    dx, dy, dz, vx, vy, vz, phi, theta, psi, p, q, r, omega1, omega2, omega3, omega4 = y\n",
    "    u = neural_network(y)\n",
    "    return dynamics(t, y, u)\n",
    "\n",
    "sol = integrate.solve_ivp(dydt, (0, 20), y_0, t_eval=t)\n",
    "\n",
    "y_sim = sol.y.T\n",
    "y_sim_w = np.array([transform_back(yi) for yi in y_sim])\n",
    "\n",
    "x, y, z, vx, vy, vz, phi, theta, psi, p, q, r, omega1, omega2, omega3, omega4 = y_sim_w.T\n",
    "u = np.array([neural_network(yi) for yi in y_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation.animate(t,x,y,z-1,phi,theta,psi,u, waypoints=[np.array([0.,0.,-1.]), np.array([-4.,0.,-1.])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-technology",
   "metadata": {},
   "source": [
    "# Flying a continuous trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quadcopter_animation import animation\n",
    "import scipy\n",
    "\n",
    "\n",
    "target1 = np.array([-2.,-2.,-1.])\n",
    "target2 = np.array([ 2.,-2.,-1.])\n",
    "target3 = np.array([ 2., 2.,-1.])\n",
    "target4 = np.array([-2., 2.,-1.])\n",
    "\n",
    "target = target2\n",
    "\n",
    "t = np.linspace(0, 10, 1000)\n",
    "t0 = 0\n",
    "\n",
    "y0_w = np.zeros(16)\n",
    "y0_w[0:3] = target1\n",
    "y0_w[12:16] = (dataset[\"omega_max\"] + dataset[\"omega_min\"])/2\n",
    "\n",
    "y0 = transform(y0_w)\n",
    "\n",
    "psi_ref = 0\n",
    "u_list = []\n",
    "target_list = []\n",
    "\n",
    "\n",
    "def dydt(t, y):\n",
    "    global target, psi_ref, u_list, t0\n",
    "    # state in world coordinates\n",
    "    y_w = transform_back(y)\n",
    "    \n",
    "    delta_pos = y_w[0:3] - target\n",
    "    if target is target2:\n",
    "        psi_ref = 0\n",
    "        normal = np.array([np.cos(np.pi*1/4), np.sin(np.pi*1/4), 0.])\n",
    "        if np.linalg.norm(delta_pos) < 0.8:\n",
    "            target = target3\n",
    "    elif target is target3:\n",
    "        psi_ref = np.pi/2\n",
    "        normal = np.array([np.cos(np.pi*3/4), np.sin(np.pi*3/4), 0.])\n",
    "        if np.linalg.norm(delta_pos) < 0.8:\n",
    "            target = target4\n",
    "    elif target is target4:\n",
    "        psi_ref = np.pi\n",
    "        normal = np.array([np.cos(np.pi*5/4), np.sin(np.pi*5/4), 0.])\n",
    "        if np.linalg.norm(delta_pos) < 0.8:\n",
    "            target = target1\n",
    "    elif target is target1:\n",
    "        psi_ref = -np.pi/2\n",
    "        normal = np.array([np.cos(np.pi*7/4), np.sin(np.pi*7/4), 0.])\n",
    "        if np.linalg.norm(delta_pos) < 0.8:\n",
    "            target = target2\n",
    "    \n",
    "           \n",
    "    \n",
    "    # describe state relative to target\n",
    "    y_w[0:3] -= target\n",
    "    \n",
    "    nn_input = transform(y_w)\n",
    "    \n",
    "    nn_input[8] -= psi_ref\n",
    "    \n",
    "    while nn_input[8] > np.pi:\n",
    "        nn_input[8] -= np.pi*2\n",
    "    while nn_input[8] < -np.pi:\n",
    "        nn_input[8] += np.pi*2\n",
    "    \n",
    "    \n",
    "    # control input\n",
    "    u = neural_network(nn_input) #,Mx,My,Mz)\n",
    "    u_list.append((t, u))\n",
    "    target_list.append((t, target))\n",
    "    \n",
    "    d_y = dynamics(t, y, u)\n",
    "    return d_y\n",
    "    \n",
    "\n",
    "sol = integrate.solve_ivp(dydt, (t[0], t[-1]), y0, t_eval=t)\n",
    "y_sim = sol.y.T\n",
    "y_sim_w = np.array([transform_back(yi) for yi in y_sim])\n",
    "\n",
    "x, y, z, vx, vy, vz, phi, theta, psi = y_sim_w[:, 0:9].T\n",
    "\n",
    "t_ = np.array([ti for ti, ui in u_list])\n",
    "u_ = np.array([ui for ti, ui in u_list])\n",
    "u_ = scipy.interpolate.interp1d(t_, u_, axis=0, fill_value=\"extrapolate\")\n",
    "u_ = u_(t)\n",
    "\n",
    "t_ = np.array([ti for ti, targeti in target_list])\n",
    "target_ = np.array([targeti for ti, targeti in target_list])\n",
    "target_ = scipy.interpolate.interp1d(t_, target_, axis=0, fill_value=\"extrapolate\")\n",
    "target_ = target_(t)\n",
    "\n",
    "animation.animate(t,x,y,z,phi,theta,psi,u_, target=target_, waypoints=[target1,target2,target3,target4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb82825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=6)\n",
    "cmap = cm.jet\n",
    "\n",
    "def color_plot(x_axis, y_axis, color_axis):\n",
    "    step = 10\n",
    "    for i in reversed(range(step,len(x_axis),step)):\n",
    "        ax = plt.gca()\n",
    "        ax.plot([x_axis[i-step], x_axis[i]], [y_axis[i-step], y_axis[i]], color=cmap(norm(color_axis[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_plot(y,x,V)\n",
    "plt.xlabel('y [m]')\n",
    "plt.ylabel('x [m]')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), label='V [m/s]')\n",
    "plt.title('Simulation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (drone_env)",
   "language": "python",
   "name": "drone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
